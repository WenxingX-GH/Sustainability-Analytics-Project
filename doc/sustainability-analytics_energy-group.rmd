---
title: "Sustainability Analytics: Energy & Weather Data Report"
author: "Barbara Maier, Wenxing Xu, Güney Usta"
date: "2025-09-18"
output:
  html_document:
    toc: true
    toc_float: true
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
# This chunk sets global options for the entire document.
# include=FALSE hides this chunk from the final rendered report.
knitr::opts_chunk$set(
  echo = TRUE,       # Display the R code in the output document
  warning = FALSE,   # Suppress warnings
  message = FALSE,   # Suppress messages
  fig.width = 10,    # Default width for figures in inches    
  fig.height = 6     # Default height for figures in inches
)
```

```{r libraries}
# This chunk loads all the necessary R packages for the analysis.
library(dplyr)
library(readr)
library(tidyr)
library(lubridate)
library(janitor)
library(stringr)
library(ggplot2)
library(patchwork) # Used for arranging multiple plots
```

# Introduction

The transition to renewable energy sources presents both opportunities and challenges for homeowners. Optimizing the use of technologies like photovoltaic (PV) systems and electric vehicles (EVs) requires a deep understanding of energy consumption patterns, which are heavily influenced by local weather.

This analysis examines historical energy and weather data from a residence in Baden, Switzerland. By correlating the household's energy consumption with local weather patterns, we aim to develop data-driven recommendations to help the homeowner increase their self-consumption of clean energy, reduce costs, and contribute to a more sustainable energy system.

# Datasets & Datasources

This analysis utilizes two primary data sources: detailed energy data for the household and local weather data. The table below provides a comprehensive overview of each source.

> **Licensing note:** *Von Google lizenziert* where applicable; MeteoSwiss data is provided under the Swiss OGD framework.

| Dataset | Provider | Description | Key variables used |
|---|---|---|---|
| **Household Energy Profile** | AEW Energie AG | High‑resolution energy metrics for a residential property (Wynemattestrasse 17) over ~5 years: generation, consumption, and grid interaction. | `pv_production_k_wh` – PV energy production (kWh)<br>`consumption_base_load_k_wh` – Base load (e.g., refrigerator, standby)<br>`consumption_heat_pump_k_wh` – Heat pump consumption<br>`consumption_ev_charging_k_wh` – EV charging consumption<br>`grid_feed_in_pv_k_wh` – Surplus PV fed into grid<br>`grid_import_total_k_wh` – Total grid import |
| **Historical Weather Data** | MeteoSwiss | Hourly weather observations (OGD) used to correlate energy patterns with environmental conditions. | `temperature_c` – Mean air temperature (°C)<br>`humidity_pct` – Mean relative humidity (%)<br>`wind_speed_ms` – Mean wind speed (m/s) |

# Data Wrangling

This section includes the functions and steps to load, clean, process, and merge the datasets.

## Function to Load and Process Energy Data

This function is designed to handle the specific format of the AEW energy data. It correctly parses timestamps (including the "24:00" format, which is treated as the start of the next day), cleans column names, and aggregates the data to an hourly resolution.

```{r functions-energy}
load_and_process_energy_data <- function(file_path,
                                         tz_out = "UTC",
                                         aggregate_to_hour = TRUE,
                                         complete_hours = TRUE) {

  energy_long <- read_csv(file_path, show_col_types = FALSE, guess_max = 2e5) %>%
    clean_names() %>%
    rename(ts_raw = timestamp)

  energy_wide <- energy_long %>%
    mutate(
      # Detect and handle "... 24:00" timestamps
      is_24 = str_detect(ts_raw, "(\\s|T)24:00(:00)?$"),
      ts_norm = str_replace(ts_raw, "(\\s|T)24:00(:00)?$", " 00:00:00"),
      timestamp = parse_date_time(ts_norm,
                                  orders = c("ymd HMS","ymd HM","dmy HMS","dmy HM"),
                                  tz = tz_out),
      timestamp = if_else(is_24, timestamp + days(1), timestamp),
      value = suppressWarnings(as.numeric(value))
    ) %>%
    filter(!is.na(timestamp)) %>%
    group_by(timestamp, metric) %>%
    summarise(value = mean(value, na.rm = TRUE), .groups = "drop") %>%
    pivot_wider(names_from = metric, values_from = value) %>%
    clean_names()

  if (aggregate_to_hour) {
    energy_wide <- energy_wide %>% mutate(timestamp = floor_date(timestamp, "hour"))
    kwh_cols  <- grep("_k_wh$", names(energy_wide), value = TRUE)
    other_num <- setdiff(names(energy_wide)[sapply(energy_wide, is.numeric)], kwh_cols)

    energy_wide <- energy_wide %>%
      group_by(timestamp) %>%
      summarise(
        across(all_of(kwh_cols),  ~ sum(.x, na.rm = TRUE)),
        across(all_of(other_num), ~ mean(.x, na.rm = TRUE)),
        .groups = "drop"
      )
  }

  if (complete_hours) {
    energy_wide <- energy_wide %>%
      arrange(timestamp) %>%
      complete(timestamp = seq(from = floor_date(min(timestamp), "hour"),
                               to   = floor_date(max(timestamp), "hour"),
                               by   = "hour"))
  }

  energy_wide %>%
    arrange(timestamp) %>%
    mutate(date = as_date(timestamp))
}
```

## Function to Load and Process MeteoSwiss Weather Data

This function loads the semicolon-delimited weather data. It includes a helper to robustly parse numbers that might use either a dot or a comma as a decimal mark.

```{r functions-weather}
# Helper to parse numbers regardless of decimal mark
parse_numeric_smart <- function(x) {
  x_chr <- as.character(x)
  v_dot   <- parse_number(x_chr, locale = locale(decimal_mark = ".", grouping_mark = ","))
  v_comma <- parse_number(x_chr, locale = locale(decimal_mark = ",", grouping_mark = "."))
  if (sum(!is.na(v_comma)) > sum(!is.na(v_dot))) v_comma else v_dot
}

load_and_process_weather_data <- function(file_path_weatherdata,
                                          station = NULL, tz_out = "UTC") {
  weather_raw <- read_delim(
    file_path_weatherdata,
    delim = ";",
    show_col_types = FALSE,
    guess_max = 2e5
  ) %>%
    clean_names() %>%
    rename(
      station       = station_abbr,
      ts_raw        = reference_timestamp,
      temperature_c = tre200h0,
      humidity_pct  = ure200h0,
      wind_speed_ms = fkl010h0
    ) %>%
    mutate(
      timestamp = parse_date_time(ts_raw, orders = c("dmy HM","dmy HMS"), tz = tz_out),
      timestamp = floor_date(timestamp, "hour"),
      date      = as_date(timestamp),
      temperature_c = parse_numeric_smart(temperature_c),
      humidity_pct  = parse_numeric_smart(humidity_pct),
      wind_speed_ms = parse_numeric_smart(wind_speed_ms)
    ) %>%
    filter(!is.na(timestamp), date >= as_date("2020-01-01"))

  weather_raw %>%
    group_by(timestamp) %>%
    summarise(
      temperature_c = mean(temperature_c, na.rm = TRUE),
      humidity_pct  = mean(humidity_pct,  na.rm = TRUE),
      wind_speed_ms = mean(wind_speed_ms, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    arrange(timestamp) %>%
    mutate(date = as_date(timestamp))
}
```

## Execute Wrangling and Merging

This chunk executes the functions defined above to load, process, and merge the two datasets into a final, hourly dataframe.

```{r wrangle-merge}
# Define file paths
energy_file  <- "../data/household_energy_profile_Wynemattestrasse_17_5_years.csv"
weather_file <- "../data/ogd-smn_bus_h_historical_2020-2029.csv"

# Process data using the functions
energy_df  <- load_and_process_energy_data(energy_file)
weather_df <- load_and_process_weather_data(weather_file)

# Merge the two dataframes into one
final_df_h <- left_join(energy_df, weather_df, by = "timestamp") %>% 
  select(-date.y) %>% 
  rename(date = date.x)

# Display the first few rows of the final merged dataset
head(final_df_h)

# Save the final hourly dataset to a CSV file
write_csv(final_df_h, "final_df_h.csv")
```

# Exploratory Data Analysis (EDA)

## Daily Aggregation

To analyze broader trends, we aggregate the hourly data into daily summaries. Energy metrics are summed, while weather metrics are averaged for each day.

```{r daily-aggregation}
self_col <- "self_consumption_pv_k_wh"

final_df_d <- final_df_h %>%
  group_by(date) %>%
  summarise(
    # Energy (sum over 24 hours per day)
    pv_production_k_wh = sum(pv_production_k_wh, na.rm = TRUE),
    consumption_base_load_k_wh = sum(consumption_base_load_k_wh, na.rm = TRUE),
    consumption_heat_pump_k_wh = sum(consumption_heat_pump_k_wh, na.rm = TRUE),
    consumption_ev_charging_k_wh = sum(consumption_ev_charging_k_wh, na.rm = TRUE),
    grid_feed_in_pv_k_wh = sum(grid_feed_in_pv_k_wh, na.rm = TRUE),
    grid_import_total_k_wh = sum(grid_import_total_k_wh, na.rm = TRUE),
    self_consumption_pv_k_wh = if (self_col %in% names(final_df_h)) sum(.data[[self_col]], na.rm = TRUE) else NA_real_,
    
    # Weather (daily averages)
    temperature_daily_C = mean(temperature_c, na.rm = TRUE),
    humidity_daily_pct = mean(humidity_pct, na.rm = TRUE),
    wind_speed_daily_ms = mean(wind_speed_ms, na.rm = TRUE)
  ) %>%
  ungroup()

# Display the first few rows of the daily aggregated data
head(final_df_d)

# Save the daily aggregated data to a CSV file
write_csv(final_df_d, "final_df_d.csv")
```

## Time Series Visualization

The following plots show the behavior of key energy and weather variables over the entire time period. This is useful for identifying seasonality, trends, and potential anomalies.

```{r time-series-plots, fig.height=12}
# Define the list of variables to plot
plot_vars <- c(
  "consumption_base_load_k_wh", "consumption_heat_pump_k_wh",
  "consumption_ev_charging_k_wh", "grid_feed_in_pv_k_wh",
  "grid_import_total_k_wh", "self_consumption_pv_k_wh",
  "pv_production_k_wh", "temperature_c", "humidity_pct", "wind_speed_ms"
)

# Create a list of plots
plots <- lapply(plot_vars, function(var) {
  if (!var %in% names(final_df_h)) return(NULL)
  ggplot(final_df_h, aes(x = timestamp, y = .data[[var]])) +
    geom_line(linewidth = 0.5) +
    labs(title = var, x = "Time", y = "Value") +
    theme_minimal()
})

# Remove NULLs (in case some variables are absent)
plots <- Filter(Negate(is.null), plots)

# Arrange all plots in a grid for easier comparison
wrap_plots(plots, ncol = 2)
```

# Modeling

*TODO: Add modeling steps here.*

# Results and Discussion

*TODO: Add results and discussion here.*
